Multi-Agent RAG Chatbot API
This project is a sophisticated, multi-agent Retrieval-Augmented Generation (RAG) chatbot API built with FastAPI and powered by Azure OpenAI. It provides a secure, stateful, and conversational interface capable of answering questions from multiple, distinct knowledge bases.

The architecture is designed to be robust, scalable, and production-ready, featuring JWT authentication, real-time streaming responses, and a powerful conversational memory system managed by LangGraph.

High-Level Architecture
This diagram illustrates the flow of a user request through the system, from authentication to the final streaming response generated by the RAG agent.

Key Features
Multi-Agent RAG: The chatbot can intelligently route user queries to different specialized agents, each with its own knowledge base (e.g., Help Guides, Pricing, Website Content, TaxGenii API).

Conversational Memory: Utilizes LangGraph to maintain context, understand follow-up questions, and provide coherent, multi-turn conversations.

Stateful Chat Sessions: Full chat history is securely stored in a database, allowing users to resume conversations.

Real-time Streaming: Responses are streamed token-by-token using Server-Sent Events (SSE), providing an excellent user experience.

Secure Authentication: Endpoints are protected using encrypted JWT tokens, with a full register/login/logout flow.

Robust Database Schema: Uses SQLAlchemy and Alembic for a version-controlled, relational database schema that stores users, chat sessions, messages, and RAG sources for full traceability.

Asynchronous Architecture: Built on FastAPI and asyncio, ensuring high performance and concurrency.

Technology Stack
The project leverages a modern, high-performance technology stack.

Backend Framework: FastAPI

Language: Python 3.11+

AI Orchestration: LangGraph

LLM Provider: Azure OpenAI

Database: PostgreSQL (or MySQL/SQLite) with SQLAlchemy ORM

Database Migrations: Alembic

Authentication: JWT (JSON Web Tokens) with Passlib for hashing

API Schemas: Pydantic V2

Async HTTP Client: HTTPX

Project Structure
/
├── alembic/                  # Database migration scripts
├── app/
│   ├── api/v1/               # API endpoints (routers)
│   ├── core/                 # Core logic (database connection, config)
│   ├── models/               # SQLAlchemy database models
│   ├── repositories/         # Database query logic
│   ├── schemas/              # Pydantic API schemas
│   ├── services/             # Business logic (ChatService, AuthService, etc.)
│   └── dependencies.py       # Shared dependencies (e.g., get_current_user)
├── main.py                   # Main FastAPI application entrypoint
└── alembic.ini               # Alembic configuration

Setup and Installation
Clone the Repository

git clone <your-repo-url>
cd <your-repo-name>

Create and Activate a Virtual Environment

python -m venv venv
source venv/bin/activate

Install Dependencies

pip install -r requirements.txt

Configure Environment Variables
Create a .env file in the root directory and populate it with your credentials:

# Database
DATABASE_URL="postgresql+asyncpg://user:password@host:port/dbname"

# Azure OpenAI
AZURE_OPENAI_API_KEY="your_api_key"
AZURE_OPENAI_DEPLOYMENT="your_deployment_name"
AZURE_OPEN_API_ENDPOINT="https://your_[endpoint.openai.azure.com/](https://endpoint.openai.azure.com/)"
AZURE_OPENAI_API_VERSION="2023-05-15"

# Azure Search
AZURE_ENDPOINT="https://your_search_service.search.windows.net"
AZURE_KEY="your_search_api_key"

# JWT Authentication
JWT_SECRET_KEY="your_super_secret_key"
JWT_ALGORITHM="HS256"
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=60
JWT_ENCRYPTION_KEY="a_secure_32_character_encryption_key"

Run Database Migrations
This will create all the necessary tables in your database.

alembic upgrade head

Run the Application

uvicorn main:app --reload --port 8001

The API will now be running at http://127.0.0.1:8001.

API Usage Example (cURL)
The following diagram illustrates the standard API workflow for a new user.

Register a User

curl -X POST [http://127.0.0.1:8001/api/v1/auth/register](http://127.0.0.1:8001/api/v1/auth/register) \
-H "Content-Type: application/json" \
-d '{"username": "testuser", "email": "test@example.com", "password": "a_strong_password"}'

Login to Get a Token

curl -X POST [http://127.0.0.1:8001/api/v1/auth/token](http://127.0.0.1:8001/api/v1/auth/token) \
-H "Content-Type: application/x-www-form-urlencoded" \
-d "username=testuser&password=a_strong_password"

Copy the access_token from the response.

Create a New Chat Session

curl -X POST [http://127.0.0.1:8001/api/v1/chat/new-chat](http://127.0.0.1:8001/api/v1/chat/new-chat) \
-H "Authorization: Bearer <YOUR_JWT_TOKEN>"

Copy the chat_id from the response.

Send a Streaming Message

curl -N -X POST [http://127.0.0.1:8001/api/v1/chat/message](http://127.0.0.1:8001/api/v1/chat/chat-lg) \
-H "Content-Type: application/json" \
-H "Authorization: Bearer <YOUR_JWT_TOKEN>" \
-d '{"chat_id": 1, "message": "What is the nano pricing plan?", "stream": true}'

You will see the response stream into your terminal in real-time.